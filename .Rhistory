xlab = "heatwave impact (mortality in heatwave year)", ylab = "extinction risk")
# Highlight the threshold severity at which the population extinction risk
# exceeds 5%
abline(h = 0.5, col = "red", lwd = 2)
### Basic life history parameters
set.seed(1)
# Reproductive rate, or maximum rate of growth
R_max <- 1.021
# Initial abundance of the population
Init_N <- 160
# Carrying capacity of the habitat for this species
K <- 200
# Next we know that the true population growth rate will vary
#  a bit year-to-year just from natural fluctuating conditions.
# This is known as environmental stochasticity.
# An estimate of the standard deviation of the annual growth rate
SD_anngrowth <- 0.031
# Next, we know that our populations might be subject to rare but devastating
# catastrophes. These can be natural events like Heatwaves or disease epidemics,
# or anthropogenic impacts like the Deepwater Horizon oil spill.
# We'll use a heatwave as an example
# 5% chance of major heatwave ( or 1 every 20 years)
Heatwave_prob <- 0
# 25% of population can survive a heatwave
Heatwave_lambda <- 0.25
# Basic simulation parameters
# Number of years
nyears <- 100
# Number of replicate simulations to run
nreps <- 500
# Now we'll set up a couple of functions to calculate our population growth
# One important function that we will add in is density-dependence. This means
# that as our population gets close to the carrying capacity, the growth rate
# will begin to decrease to take into account that food and other resources will
# being to become scarce
# Computing next-year abundance with a density-dependent effect based on K
# (known as the Ricker model)
Ricker <- function(prev_abund) {
prev_abund * exp(log(rnorm(1, R_max, SD_anngrowth)) * (1 - (prev_abund / K)))
}
# Now we can estimate the annual population size over time, taking into account
# our life history parameters, density-dependence, and our probability
# of a catastrophe occurring
PVAdemo <- function(nreps, nyears, Init_N, R_max, K, Heatwave_prob, Heatwave_lambda) {
PopArray2 <- array(0, dim = c((nyears + 1), nreps)) # set up storage array
## start looping through replicates
for (rep in 1:nreps) {
# set initial abundance
PopArray2[1, rep] <- Init_N # set the initial abundance
### loop through years
for (y in 2:(nyears + 1)) {
### stochasticity and d-d
nextyear <- max(0, trunc(Ricker(PopArray2[y - 1, rep])))
### catastrophe
if (runif(1) < Heatwave_prob) nextyear <- nextyear * Heatwave_lambda
PopArray2[y, rep] <- nextyear
}
}
return(PopArray2)
}
# Run the default population viability analysis
Default <- PVAdemo(nreps, nyears, Init_N, R_max, K, Heatwave_prob, Heatwave_lambda)
# Create a function for plotting the data
PlotCloud <- function(simdata) {
plot(c(1:101), simdata[, 1], col = gray(0.7), type = "l",
ylim = c(0, max(simdata)), xlab = "Years", ylab = "Abundance")
for (r in 2:ncol(simdata)) {
lines(c(1:101), simdata[, r], col = gray(0.7), type = "l")
}
}
# Default is a matrix of population sizes for each year
# and for each run of the simulation
dim(Default)
Default[1:10, 1:10]
# Plot the data
PlotCloud(Default)
mean(Default[,101])
# Calculate the probability for each future year that the population has gone
# extinct (population abundance = 0)
Extinction_byyear <- function(simdata) {
apply(simdata, 1, function(t) length(which(t == 0))) / ncol(simdata)
}
# Plot the yearly extinction risk
plot(c(1:101), Extinction_byyear(Default), type = "l", lwd = 2, xlab = "year",
ylab = "extinction risk")
# Add a line to show when extinction risk crosses 5 %
abline(h = 0.05, col = "red", lwd = 2)
hist(Default[nrow(Default), ], xlab = "Final abundance after 100 years",
ylab = "Number of replicates", main = "")
# Highlight our initial population size in green
abline(v = Init_N, col = "green", lwd = 2)
# plot probabilities of different severeties of decline
declines <- seq(0, 100, by = 1)
declineprob <- numeric(length(declines))
for (s in 1:length(declines)) {
declineprob[s] <- length(which(Default[nrow(Default), ] <
(Init_N - (declines[s] / 100) * Init_N))) / ncol(Default)
}
plot(declines, declineprob, type = "l", lwd = 2,
xlab = "Decline threshold (percent)",
ylab = "Probability of falling below threshold")
abline(v = 50, col = "red", lwd = 2)
# Plot extinction risk as a function of heatwave severity
# Calculate extinction risk
Exctinction_risk <- function(simdata) {
length(which(simdata[nrow(simdata), ] == 0)) / ncol(simdata)
}
# Create a range of heatwave mortality levels (lambdas)
heatwave_lambdas <- seq(0.9, 0.1, by = -0.05)
# Run the PVA for all these scenarios and calculate extinction risk
all_scenarios <- numeric(length(heatwave_lambdas))
for (scenario in 1:length(heatwave_lambdas)) {
PVA <- PVAdemo(nreps, nyears, Init_N, R_max, K, Heatwave_prob, heatwave_lambdas[scenario])
all_scenarios[scenario] <- Exctinction_risk(PVA)
}
# Plot the 100-year extinction risk for all scenarios
plot(1 - heatwave_lambdas, all_scenarios, type = "l", cex = 2,
xlab = "heatwave impact (mortality in heatwave year)", ylab = "extinction risk")
# Highlight the threshold severity at which the population extinction risk
# exceeds 5%
abline(h = 0.5, col = "red", lwd = 2)
### Basic life history parameters
set.seed(1)
# Reproductive rate, or maximum rate of growth
R_max <- 1.04
# Initial abundance of the population
Init_N <- 50
# Carrying capacity of the habitat for this species
K <- 200
# Next we know that the true population growth rate will vary
#  a bit year-to-year just from natural fluctuating conditions.
# This is known as environmental stochasticity.
# An estimate of the standard deviation of the annual growth rate
SD_anngrowth <- 0.10
# Next, we know that our populations might be subject to rare but devastating
# catastrophes. These can be natural events like Heatwaves or disease epidemics,
# or anthropogenic impacts like the Deepwater Horizon oil spill.
# We'll use a heatwave as an example
# 5% chance of major heatwave ( or 1 every 20 years)
Heatwave_prob <- 0.05
# 25% of population can survive a heatwave
Heatwave_lambda <- 0.25
# Basic simulation parameters
# Number of years
nyears <- 100
# Number of replicate simulations to run
nreps <- 500
# Now we'll set up a couple of functions to calculate our population growth
# One important function that we will add in is density-dependence. This means
# that as our population gets close to the carrying capacity, the growth rate
# will begin to decrease to take into account that food and other resources will
# being to become scarce
# Computing next-year abundance with a density-dependent effect based on K
# (known as the Ricker model)
Ricker <- function(prev_abund) {
prev_abund * exp(log(rnorm(1, R_max, SD_anngrowth)) * (1 - (prev_abund / K)))
}
# Now we can estimate the annual population size over time, taking into account
# our life history parameters, density-dependence, and our probability
# of a catastrophe occurring
PVAdemo <- function(nreps, nyears, Init_N, R_max, K, Heatwave_prob, Heatwave_lambda) {
PopArray2 <- array(0, dim = c((nyears + 1), nreps)) # set up storage array
## start looping through replicates
for (rep in 1:nreps) {
# set initial abundance
PopArray2[1, rep] <- Init_N # set the initial abundance
### loop through years
for (y in 2:(nyears + 1)) {
### stochasticity and d-d
nextyear <- max(0, trunc(Ricker(PopArray2[y - 1, rep])))
### catastrophe
if (runif(1) < Heatwave_prob) nextyear <- nextyear * Heatwave_lambda
PopArray2[y, rep] <- nextyear
}
}
return(PopArray2)
}
# Run the default population viability analysis
Default <- PVAdemo(nreps, nyears, Init_N, R_max, K, Heatwave_prob, Heatwave_lambda)
# Create a function for plotting the data
PlotCloud <- function(simdata) {
plot(c(1:101), simdata[, 1], col = gray(0.7), type = "l",
ylim = c(0, max(simdata)), xlab = "Years", ylab = "Abundance")
for (r in 2:ncol(simdata)) {
lines(c(1:101), simdata[, r], col = gray(0.7), type = "l")
}
}
# Default is a matrix of population sizes for each year
# and for each run of the simulation
dim(Default)
Default[1:10, 1:10]
# Plot the data
PlotCloud(Default)
Default[,101]
### Basic life history parameters
set.seed(150)
# Reproductive rate, or maximum rate of growth
R_max <- 1.021
# Initial abundance of the population
Init_N <- 175
# Carrying capacity of the habitat for this species
K <- 200
# Next we know that the true population growth rate will vary
#  a bit year-to-year just from natural fluctuating conditions.
# This is known as environmental stochasticity.
# An estimate of the standard deviation of the annual growth rate
SD_anngrowth <- 0.031
# Next, we know that our populations might be subject to rare but devastating
# catastrophes. These can be natural events like Heatwaves or disease epidemics,
# or anthropogenic impacts like the Deepwater Horizon oil spill.
# We'll use a heatwave as an example
# 5% chance of major heatwave ( or 1 every 20 years)
Heatwave_prob <- 0.0
# 25% of population can survive a heatwave
Heatwave_lambda <- 0.25
# Basic simulation parameters
# Number of years
nyears <- 100
# Number of replicate simulations to run
nreps <- 500
# Now we'll set up a couple of functions to calculate our population growth
# One important function that we will add in is density-dependence. This means
# that as our population gets close to the carrying capacity, the growth rate
# will begin to decrease to take into account that food and other resources will
# being to become scarce
# Computing next-year abundance with a density-dependent effect based on K
# (known as the Ricker model)
Ricker <- function(prev_abund) {
prev_abund * exp(log(rnorm(1, R_max, SD_anngrowth)) * (1 - (prev_abund / K)))
}
# Now we can estimate the annual population size over time, taking into account
# our life history parameters, density-dependence, and our probability
# of a catastrophe occurring
PVAdemo <- function(nreps, nyears, Init_N, R_max, K, Heatwave_prob, Heatwave_lambda) {
PopArray2 <- array(0, dim = c((nyears + 1), nreps)) # set up storage array
## start looping through replicates
for (rep in 1:nreps) {
# set initial abundance
PopArray2[1, rep] <- Init_N # set the initial abundance
### loop through years
for (y in 2:(nyears + 1)) {
### stochasticity and d-d
nextyear <- max(0, trunc(Ricker(PopArray2[y - 1, rep])))
### catastrophe
if (runif(1) < Heatwave_prob) nextyear <- nextyear * Heatwave_lambda
PopArray2[y, rep] <- nextyear
}
}
return(PopArray2)
}
# Run the default population viability analysis
Default <- PVAdemo(nreps, nyears, Init_N, R_max, K, Heatwave_prob, Heatwave_lambda)
# Create a function for plotting the data
PlotCloud <- function(simdata) {
plot(c(1:101), simdata[, 1], col = gray(0.7), type = "l",
ylim = c(0, max(simdata)), xlab = "Years", ylab = "Abundance")
for (r in 2:ncol(simdata)) {
lines(c(1:101), simdata[, r], col = gray(0.7), type = "l")
}
}
# Default is a matrix of population sizes for each year
# and for each run of the simulation
dim(Default)
Default[1:10, 1:10]
# Plot the data
PlotCloud(Default)
Default[,101]
Default[,101]
install.packages("usethis")
setwd("C:/TAMUG/Foroughirad Lab/Kin Association")
install.packages(SocGen)
remotes::install_github("vjf2/SocGen")
library(SocGen) ## remotes::install_github("vjf2/SocGen")
library(readxl)
# Read in life history data
lh <- read.csv("Data/LifeHistory_20241009.csv")
lh$Birth.Date <- as.Date(lh$Birth.Date)
lh$Death.Date <- as.Date(lh$Death.Date)
View(lh)
# Read in survey sightings
asurveys <- read.csv("Data/SurveyDolphin_20240819.csv")
asurveys$Observation.Date <- as.Date(asurveys$Observation.Date)
allF <- lh$Dolphin.ID[which(lh$Sex == "FEMALE")]
allF <- asurveys[which(asurveys$Dolphin.ID %in% allF), c("Dolphin.ID", "Observation.Date")]
View(allF)
allF <- allF[!duplicated(allF), ]
View(allF)
# Add birthdate into allF
allF$birthdate <- lh$Birth.Date[match(
allF$Dolphin.ID,
lh$Dolphin.ID
)]
View(allF)
calves <- lh[which(lh$Mother.ID != ""), ]
View(calves)
View(calves)
calves$pregnantstart <- calves$Birth.Date - 365
calves$cycstart6m <- calves$pregnantstart - (365 / 2)
calves$cycresume <- calves$Birth.Date + (365 * 2)
calves$cycresumeD <- ifelse(!is.na(calves$Death.Date) & calves$Death.Date < calves$cycresume, calves$Death.Date, calves$cycresume)
calves$cycresumeD <- as.Date(calves$cycresumeD, origin = "1970-01-01")
calves <- calves[, c("Dolphin.ID", "Dolphin.Name", "Mother.ID", "Birth.Date", "Death.Date", "pregnantstart", "cycstart6m", "cycresume", "cycresumeD")]
dates <- sort(unique(allF$Observation.Date))
pregnant <- schedulize(
data = calves, id = "Dolphin.ID",
start = "pregnantstart", end = "Birth.Date",
dates = dates,
format = c("mask")
)
View(pregnant)
colnames(pregnant) <- as.character(sort(unique(allF$Observation.Date)))
preg <- mat2dat(pregnant, "pregnant")
names(preg)[1] <- "pregID"
preg$mom <- calves$Mother.ID[match(preg$pregID, calves$Dolphin.ID)]
View(preg)
View(calves)
lactating <- schedulize(
data = calves, id = "Dolphin.ID",
start = "Birth.Date", end = "cycresumeD",
dates = dates,
format = c("mask")
)
colnames(lactating) <- as.character(sort(unique(allF$Observation.Date)))
lact <- mat2dat(lactating, "lactating")
names(lact)[1] <- "lactID"
lact$mom <- calves$Mother.ID[match(lact$lactID, calves$Dolphin.ID)]
View(lact)
defcyc <- schedulize(
data = calves, id = "Dolphin.ID",
start = "cycstart6m", end = "pregnantstart",
dates = dates,
format = c("mask")
)
View(lact)
colnames(defcyc) <- as.character(sort(unique(allF$Observation.Date)))
cyc <- mat2dat(defcyc, "cycling")
names(cyc)[1] <- "cycID"
cyc$mom <- calves$Mother.ID[match(cyc$cycID, calves$Dolphin.ID)]
# Merge into allF, then count adult males and merge total group size
allF <- merge(allF, preg,
by.x = c("Dolphin.ID", "Observation.Date"),
by.y = c("mom", "ID2"), all.x = TRUE
)
allF <- merge(allF, lact,
by.x = c("Dolphin.ID", "Observation.Date"),
by.y = c("mom", "ID2"), all.x = TRUE
)
allF <- merge(allF, cyc,
by.x = c("Dolphin.ID", "Observation.Date"),
by.y = c("mom", "ID2"), all.x = TRUE
)
allF$age <- as.numeric(allF$Observation.Date - allF$birthdate) / 365.25
allF$mature <- ifelse(allF$age >= 11, "yes", "no")
allF$mature <- ifelse(!is.na(allF$cycling), "yes", allF$mature)
allF$mature <- ifelse(!is.na(allF$pregnant), "yes", allF$mature)
allF$mature <- ifelse(!is.na(allF$lactating), "yes", allF$mature)
allF$possiblycyc <- ifelse(is.na(allF$lactating) &
is.na(allF$pregnant) &
allF$mature == "yes", 1, NA)
View(allF)
write.csv(allF, "reprodutive_status_for_females.csv", row.names = FALSE)
library(SocGen) ## remotes::install_github("vjf2/SocGen")
library(readxl)
# Read in life history data
lh <- read.csv("RawData/LifeHistory_20241009.csv")
# Read in life history data
lh <- read.csv("Data/LifeHistory_20241009.csv")
lh$Birth.Date <- as.Date(lh$Birth.Date)
lh$Death.Date <- as.Date(lh$Death.Date)
# Read in survey sightings
asurveys <- read.csv("Data/SurveyDolphin_20240819.csv")
asurveys$Observation.Date <- as.Date(asurveys$Observation.Date)
allF <- lh$Dolphin.ID[which(lh$Sex == "FEMALE")]
allF <- asurveys[which(asurveys$Dolphin.ID %in% allF), c("Dolphin.ID", "Observation.Date")]
allF <- allF[!duplicated(allF), ]
# Add birthdate into allF
allF$birthdate <- lh$Birth.Date[match(
allF$Dolphin.ID,
lh$Dolphin.ID
)]
calves <- lh[which(lh$Mother.ID != ""), ]
calves$pregnantstart <- calves$Birth.Date - 365
calves$cycstart6m <- calves$pregnantstart - (365 / 2)
calves$cycresume <- calves$Birth.Date + (365 * 1.8)
calves$cycresumeD <- ifelse(!is.na(calves$Death.Date) & calves$Death.Date < calves$cycresume, calves$Death.Date, calves$cycresume)
calves$cycresumeD <- as.Date(calves$cycresumeD, origin = "1970-01-01")
calves <- calves[, c("Dolphin.ID", "Dolphin.Name", "Mother.ID", "Birth.Date", "Death.Date", "pregnantstart", "cycstart6m", "cycresume", "cycresumeD")]
dates <- sort(unique(allF$Observation.Date))
pregnant <- schedulize(
data = calves, id = "Dolphin.ID",
start = "pregnantstart", end = "Birth.Date",
dates = dates,
format = c("mask")
)
View(pregnant)
colnames(pregnant) <- as.character(sort(unique(allF$Observation.Date)))
preg <- mat2dat(pregnant, "pregnant")
names(preg)[1] <- "pregID"
preg$mom <- calves$Mother.ID[match(preg$pregID, calves$Dolphin.ID)]
View(preg)
lactating <- schedulize(
data = calves, id = "Dolphin.ID",
start = "Birth.Date", end = "cycresumeD",
dates = dates,
format = c("mask")
)
colnames(lactating) <- as.character(sort(unique(allF$Observation.Date)))
lact <- mat2dat(lactating, "lactating")
names(lact)[1] <- "lactID"
lact$mom <- calves$Mother.ID[match(lact$lactID, calves$Dolphin.ID)]
defcyc <- schedulize(
data = calves, id = "Dolphin.ID",
start = "cycstart6m", end = "pregnantstart",
dates = dates,
format = c("mask")
)
colnames(defcyc) <- as.character(sort(unique(allF$Observation.Date)))
cyc <- mat2dat(defcyc, "cycling")
names(cyc)[1] <- "cycID"
cyc$mom <- calves$Mother.ID[match(cyc$cycID, calves$Dolphin.ID)]
# Merge into allF, then count adult males and merge total group size
allF <- merge(allF, preg,
by.x = c("Dolphin.ID", "Observation.Date"),
by.y = c("mom", "ID2"), all.x = TRUE
)
allF <- merge(allF, lact,
by.x = c("Dolphin.ID", "Observation.Date"),
by.y = c("mom", "ID2"), all.x = TRUE
)
allF <- merge(allF, cyc,
by.x = c("Dolphin.ID", "Observation.Date"),
by.y = c("mom", "ID2"), all.x = TRUE
)
allF$age <- as.numeric(allF$Observation.Date - allF$birthdate) / 365.25
allF$mature <- ifelse(allF$age >= 11, "yes", "no")
allF$mature <- ifelse(!is.na(allF$cycling), "yes", allF$mature)
allF$mature <- ifelse(!is.na(allF$pregnant), "yes", allF$mature)
allF$mature <- ifelse(!is.na(allF$lactating), "yes", allF$mature)
allF$possiblycyc <- ifelse(is.na(allF$lactating) &
is.na(allF$pregnant) &
allF$mature == "yes", 1, NA)
allF[is.na(allF)] <- 0
allF$cycling <- ifelse((allF$cycling==1 & allF$pregnant == 1),
0,
allF$cycling)
allF$pregnant <- ifelse((allF$pregnant==1 & allF$lactating == 1),
0,
allF$pregnant)
write.csv(allF, "reprodutive_status_for_females.csv", row.names = FALSE)
setwd("C:/TAMUG/Foroughirad Lab/Kin Association/temporal_kinship")
library(parallel)
library(foreach)
library(doParallel)
library(doRNG)
library(SocGen) # remotes::install_github("vjf2/SocGen")
library(sp)
library(parallel)
library(foreach)
library(doParallel)
library(doRNG)
library(SocGen) # remotes::install_github("vjf2/SocGen")
library(sp)
num_sim <- 1000 # set number of simulations to run
num_sim <- 1000 # set number of simulations to run
load("Data/home_ranges.RData")
View(home_ranges)
load("Data/surveyeffort.RData")
gridrad <- home_ranges@grid@cellsize[1] / 2
indiv_covars <- read.csv("Data/individual_covariates.csv")
View(indiv_covars)
indiv_covars$entry <- as.Date(indiv_covars$entry)
indiv_covars$depart <- as.Date(indiv_covars$depart)
dates <- names(daily_search_effort)
d <- length(dates)
schedule <- schedulize(indiv_covars, id = "Dolphin.ID", start = "entry", end = "depart",
dates = dates, format = "sim")
View(indiv_covars)
sightings <- read.csv("Data/sightings.csv")
View(sightings)
numdol <- c(table(sightings$Date))
cl <- makeCluster(detectCores() - 1)
clusterEvalQ(cl, {library(sp);library(SocGen)})
clusterExport(cl, c("d", "daily_search_effort", "home_ranges", "schedule", "num_sim", "numdol", "gridrad"))
cl <- makeCluster(detectCores() - 1)
clusterEvalQ(cl, {library(sp);library(SocGen)})
clusterExport(cl, c("d", "daily_search_effort", "home_ranges", "schedule", "num_sim", "numdol", "gridrad"))
registerDoParallel(cl)
registerDoRNG(seed = 286567440)
starttime <- Sys.time()
nest_days <- foreach(i = seq_len(d), .errorhandling = 'pass') %dopar% {
bound <- daily_search_effort[i, ]
nd <- numdol[i]
dailygrid <- home_ranges[bound, , drop = TRUE]
probweights <- colSums(dailygrid@data, na.rm = TRUE)
probweights <- probweights[names(probweights) %in% colnames(schedule)[schedule[i, ] == TRUE]]
dc <- coordinates(dailygrid)
dgdf <- dailygrid@data
holder <- replicate(num_sim, fast_random_points(probweights = probweights,
nd = nd,
dc = dc,
dgdf = dgdf,
gridrad = gridrad),
simplify = FALSE)
return(holder)
}
endtime <- Sys.time()
stopCluster(cl)
endtime - starttime # run time ~20 min on Intel(R) Core(TM) i7-8565U CPU @ 1.80GHz
# rearrange list so that days are listed within iteration
sim_surveys <- sapply(1:num_sim, function(i) lapply(nest_days, "[[", i), simplify = FALSE)
# group dolphins together using hierarchical distance-based clustering to get same average group size as in real data
groupperday <- table(sightings$Date[!duplicated(sightings$Observation.ID)])
